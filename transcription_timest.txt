[125.00-154.98] Продолжение следует...
[150.00-152.88] Появился в Казахстане.
[250.00-279.52] Всем привет! [279.52-250.00]  [250.24-NA] и в субботу.
[275.00-280.00] Все, что я могу сказать, я могу сказать, что я не могу [280.00-282.00] сказать, что я не могу сказать. [282.00-284.00] Я не могу сказать, что я не могу сказать.
[375.00-403.90] Да, давайте начнем. [403.90-375.00]  [376.00-NA] м.
[400.00-403.92] Да, давайте начнем. [403.92-400.00]  [426.06-400.00] Секунду. [429.98-NA] Старый мир, который не может быть разрушен, не может быть разрушен.
[425.00-436.12] нас сегодня ждет не то чтобы сильно большая поэтому скорее всего мы проведем ее без перерыва думаю мы [436.12-442.04] успеем где-то за час максимум все это дело рассказать но при этом заключительная лекция [442.04-452.24] в блоке первом лекции связанных с ломками такими именно больше коры историями там про модальности [452.24-425.00]  [427.76-NA] про то, как их обучают, какие там способы используют.
[450.00-454.84] историями про модальности и про то, как их обучают, какие там способы используют. [455.34-460.66] И сегодня мы, по большей части, как раз поговорим про какие-то оставшиеся модальности, [460.72-466.42] которые не успели затронуть на предыдущей лекции, и заодно немного поговорим о тех методах, [466.42-472.42] которые используют для того, чтобы вообще сервис на базе ламп какой-то свой сделать, [473.10-479.90] почему эти методы вдруг актуальны и зачем их используют, и подвинем некоторые вообще в целом итоги того,
[475.00-481.10] зачем их используют и подведем некоторые вообще в целом итоге того что мы там изучили на первом [481.10-490.04] блоке и зачем это сидел проходили да на прошлой лекции разобрали по вижу модальность такая [490.04-498.04] достаточно большая интересная сегодня будем рассматривать с вами и код и аудио и начнем [498.04-504.82] с кода вот как модальность она в целом достаточно уникальная потому что ее даже в отделу модальности [504.82-475.00]  [476.00-NA] с.
[500.00-506.10] Код как модальность, она в целом достаточно уникальная, потому что ее даже в отдел модальности в целом не всегда выносят. [506.60-511.38] Однако код сам по себе имеет достаточно много особенностей. [511.52-520.82] Во-первых, он написан на привычном для любой лоломки тексте, так или иначе, но при этом, естественно, не представляет собой естественный язык. [522.06-525.06] Для чего вообще нужен код как модальность? [525.06-500.00]  [504.94-NA] Ну, во-первых, любой разработчик в целом может сделать это.
[525.00-532.16] Ну, во-первых, любой разработчик в целом, который особенно разрабатывает подобные модальности, [532.24-535.82] он так или иначе хотел иметь какого-то универсального помощника, [535.96-539.34] который поможет достаточно быстро решать какие-то задачи, связанные с кодом, [539.44-541.30] которые возникают в целом практически всегда, [541.78-545.86] если вы разрабатываете или занимаетесь дата-сайенсом или что-то подобное. [546.24-553.26] И таких задач достаточно много, которые возникают у вас там из раза в раз в вашей жизни. [554.34-525.00]  [526.74-NA] Иногда, когда мы говорим о том, что мы не можем сделать
[550.00-553.28] у вас там из раза в раз в вашей жизни. [554.26-557.32] Иногда нужно посмотреть, где находится какой-то баг, [558.42-561.50] причем этот баг нужно найти и потом еще и понять, [561.72-564.82] каким образом нам надо сделать так, чтобы этот баг не работал, [565.28-566.54] точнее, исправить этот баг. [567.34-571.62] Нам нужно найти что-то в коде, либо своем, либо чужом. [572.76-575.76] Code-to-code retrieval достаточно часто тоже история, [575.76-577.92] которая позволяет нам решать кодовую модальность. [579.36-550.00]  [552.06-NA] Ну, естественно, мы должны поддержать эту работу.
[575.00-582.08] история, которая позволяет нам решать кодовую модальность. Естественно, самая главная вещь, [582.08-588.02] для чего кодовая модальность нужна, это генерация кода того или иного. Это может быть полностью как [588.02-594.44] рерайтинг кода, который написали, либо завершение кода, то есть какие-то универсальные помощники, [594.44-600.40] которые позволяют на основании тех данных, которых они обучились, завершить ту или иную вещь. Причем [600.40-575.00]  [579.60-NA] Потом кодовые сервисы обычно, они сочетаются с кодовыми сервисами.
[600.00-610.92] Причем кодовые сервисы обычно сочетают в себе не просто какую-то одну модельку, так они в целом сочетают множество моделей. [610.92-611.88] Сейчас секундочку. [617.38-629.34] Они сочетают множество моделей, начиная от single line модели, это как отдельная модель, где требуется завершить только одну маленькую строчку кода, [629.34-600.00]  [600.00-NA] при этом, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате, в результате,
[625.00-629.34] как отдельная модель, где требуется завершить только одну маленькую строчку кода, [629.68-636.24] при этом контекст у нее должен быть связан либо с одной строчкой кода, [636.32-640.76] либо как раз таки с кодом предыдущим каким-то, который был написан. [641.36-646.40] Это может быть мультилайн история, когда мы хотим несколько строчек кода сгенерить, [646.54-648.82] которые нам помогут выполнить ту или иную функцию. [649.20-652.30] Либо это должен быть какой-то ассистент, который понимает код [652.30-625.00]  [627.70-NA] и может провести с вами диалог, как раз-таки связанный
[650.00-655.22] какой-то ассистент который понимает код и может провести с вами диалог как раз таки связаны с [655.22-663.18] тем как вы должны там либо код свой построить либо поговорить в целом о коде либо дать задачку [663.18-672.00] комнаты кодовому ассистенту на там работу сингла и мультилай модели вот что касается данных для [672.00-650.00]  [656.72-NA] обучения здесь как раз таки всей кодовой модальности безумно сильно повезло потому что года
[675.00-684.60] всей кодовой модальности безумно сильно повезло потому что кода очень много почти весь в так или [684.60-689.94] иначе представлены в интернете коде он полезный несмотря на достаточно большое количество [689.94-697.32] дубликатов в коде обычно все бенчмарки ой бен датасеты которые там являются при троеном для [697.32-675.00]  [682.56-NA] для подобных моделей, они редусят с помощью дедубликации кода данных.
[700.00-708.52] редусит с помощью дедубликации кода данных буквально свой размер раза в два но при этом [708.52-718.78] все этих данных сильно больше чем на естественном языке на удивление и самый такой распространенный [718.78-726.90] к примеру там при тройного их дата сета для кода это стак 2 недавно вышедший там порядка [726.90-700.00]  [703.10-NA] как 900 миллиардов токенов, как в области, как в области.
[725.00-746.50] вышедший. Там порядка 900 миллиардов токенов. Как вы помните, там в российском интернете нам в целом такое даже сниться там не может на естественном языке. Да даже на англоязычном на самом деле. Не то чтобы там прям имелись такие какие-то датасеты, где столько много токенов было бы представлено. [746.50-725.00]  [733.70-NA] Весит, конечно, эта махина достаточно мощно, но даже на этом, на самом деле, разработчики не осознают, что это не так.
[750.00-769.68] Но даже на этом, на самом деле, разработчики не останавливаются, потому что у кода в целом, как у отдельной модальности, есть такое свойство, что мы всегда можем проверить правильность кода, который так или иначе нам встретится как кусок на какую-то истинность. [770.00-750.00]  [760.32-NA] Раз мы можем проводить такие проверки, мы можем написать какое-то определенное задание на сервис, связанный с генерацией подобных данных.
[775.00-780.12] определенные задания на сервисы, связанные с генерацией подобных данных, [780.64-787.22] и заасертить какую-то историю так, чтобы мы хотели, чтобы все асерты проходили по данным, [787.30-792.56] которые нам сгенерировали тайная или иная модель, и добавить такой синтетический код у нас в обучение. [793.18-800.90] Сейчас тяжело даже назвать толком долю синтетических данных внутри современных моделей, [800.90-804.82] связанных с модальностью кода, однако их достаточно много.
[800.00-802.64] моделей, связанные с модальностью кода. [803.24-806.86] Однако их достаточно много, потому что любая такая синтетика, [807.02-809.12] она так или иначе достаточно качественная. [809.54-812.38] Причем есть несколько подходов, связанные с тем, [812.56-816.40] как подобные данные можно генерить. [817.42-821.14] Есть модели достаточно эффективные, вот их тут список представленный [821.14-823.56] для генерации кода конкретно. [823.56-829.44] Это как маленькие модели, так и в целом достаточно большие некоторые представлены, [829.50-800.00]  [800.54-NA] но они эффективно не могут быть внести в работу.
[825.00-848.80] Как маленькие модели, так и в целом достаточно большие некоторые представлены, но они эффективно справляются с задачей генерации кода. Причем генерация кода у них может быть трех типов. Это либо какая-то self-instruct история, когда мы даем самой какой-то ломке, который нам будет этот код генерировать для тех или иных задач, какое-то задание, она нам на основании этого задания генерит что-то. [848.80-825.00]  [831.08-NA] Это может быть какой-то evolution instruction, когда мы хотим дать какую-то проблему.
[850.00-854.90] это evolution instruction, когда мы хотим дать какую-то проблему, [855.24-858.28] которая нам не кажется достаточно серьезной или сложной, [858.70-863.94] и мы хотим каким-то образом с помощью какой-то инструкции для ломки ее усложнить. [864.38-866.56] Причем это может быть достаточно интеративный процесс. [867.18-869.58] Мы еще поговорим о усложнении задач, связанных с кодом, [870.06-874.14] но это позволяет нам сильно увеличить сложность данных, [874.14-878.92] коли мы можем контролировать на самом деле сложность данных в обучении подобных модальностей. [879.34-850.00]  [851.06-NA] И это открывает нам новые возможности.
[875.00-879.86] можем контролировать на самом деле сложность данных в обучении подобных модальностей. Это открывает [879.86-888.48] нам достаточно большой простор в плане построения каких-то эффективных методов обучения нашей ломки, [888.54-894.44] которая будет связана с кодом. Можно использовать тот же Siriculum Learning, который дает достаточно [894.44-898.96] большую эффективность и страдает от того, что как раз у нас недостаточно данных, которые разбиты [898.96-875.00]  [876.12-877.62] по когортам сложности. [879.42-880.24] Либо это может быть OS instruction, [881.20-NA] когда у нас есть...
[900.00-909.84] либо это может быть о с instruction когда у нас есть какой-то сниппет кода и на базе такого сниппета [909.84-915.48] на может генерироваться целое множество проблем которые до этого не встречалось особо сильно [915.48-928.62] извините пожалуйста да сейчас вот которые доселе нам не встречалось либо на котором у нас там [928.62-900.00]  [901.38-NA] изначального решения.
[925.00-929.24] селе нам не встречалось, либо на которой у нас изначального [929.24-932.36] решения не было, но при этом модель хорошо умеет генерировать [932.36-933.36] подобные примеры. [933.36-941.40] В целом, у нас достаточно хорошо развиты алгоритмы, [941.40-945.62] связанные с фильтрацией подобного, точнее, какого-то [945.62-948.08] плохого хода, который мы можем встретить в нашем [948.08-953.44] притрейне, ровно как и история, связанная с дедупликацией [953.44-925.00]  [926.54-NA] Данных, которые были предоставлены в Казахстане, были предоставлены в Казахстане.
[950.00-957.56] как и истории связанные с дедупликацией данных которые нам позволяют активно как-то отсеять [957.56-965.94] нежелательные какие-то вещи в при трене ровно потому что мы умеем хорошо как раз таки некоторые вещи [965.94-973.28] заострить некоторые вещи мы семантически можем выискивать в наших данных чтобы понять насколько [973.28-979.76] код этот был похож потому что либо по выходам какого каких-то кусков кода мы можем проводить [979.76-950.00]  [950.24-NA] дико.
[975.00-981.76] что либо по выходам на какого каких-то кусков кода мы можем проводить как раз таки симулярии search [981.76-989.38] для того чтобы эффективно там где дублицировать данные ну и самое важное на самом деле для его [989.38-994.74] плане обучения кода является контроль лицензий если мы видим какой-то копирают лицензию мы к [994.74-998.52] сожалению такое обычно должны фильтровать и не использовать нашем обучении потому что чреват [998.52-975.00]  [976.16-976.80] какими-то последствиями. [979.12-980.38] С токенизацией тут тоже ничего нового нет. [981.48-NA] Определенную токенизацию
[1000.00-1002.64] С токенизацией тут тоже ничего нового нет. [1003.84-1007.38] Определенную токенизацию проводят по коду в рамках обучения модели. [1007.62-1011.34] Здесь ровно такие же проблемы, как у обычных LLAM. [1011.48-1013.54] Тут ничего в целом нового нет. [1014.08-1019.20] Каким-то образом дезаблюцируют код, используют ровно те же техники, которые для естественного языка. [1019.82-1020.54] В целом все понятно. [1021.82-1024.24] Что можно поменять в обучении LLAM? [1024.42-1026.86] На самом деле можно не менять ровным счетом ничего. [1026.86-1000.00]  [1002.00-NA] Просто взяв большой пайл...
[1025.00-1032.90] не менять ровным счетом ничего просто взяв большой пайл там естественного языка для того чтобы у нас [1032.90-1039.62] модель понимал инструкции и взять тоже кучу данных связанных с кодом все это дело вместе как-то [1039.62-1047.02] обучить подружить и у нас появится неплохой такой помощник но можно понятное дело взять какую-то [1047.02-1053.92] готовую лампу которую у нас обучена на естественном языке разморозить несколько слоев также обучить [1053.92-1025.00]  [1026.06-NA] И на коде тоже проблема.
[1050.00-1055.84] естественном языке, разморозить несколько слоев, также обучить на коде, тоже проблем не возникнет, [1055.98-1062.38] можно добавить какую-то голову, можно заадаптить под какую-то нашу историю, которая нам интересна. [1062.66-1067.08] И все эти методы, они достаточно стандартные в целом для обучения простых LLM, [1067.18-1073.72] просто новых задач на естественном языке, и при этом они достаточно эффективны для кода, [1073.84-1078.54] как для модальности, и мы тут как раз-таки сейчас каких-то определенных проблем не встречаем, [1078.54-1050.00]  [1051.00-1052.00] появляющимися в мире. Хотя хотели бы иметь в виду и другие, но не могли. [1052.00-1053.00] В этом случае, в основном, мы должны поддерживать и [1053.00-1054.00] поддерживать, и поддерживать, и поддерживать, и поддерживать [1054.00-1055.00] и поддерживать, и поддерживать, и поддерживать, и поддерживать, [1055.00-1056.00] и поддерживать, и поддерживать, и поддерживать, и поддерживать, [1056.00-1057.00] и поддерживать, и поддерживать, и поддерживать, и поддерживать, [1057.00-1058.00] и поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, [1058.00-1059.00] и поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, и [1059.00-1060.00] поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, и [1060.00-1061.00] поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, и [1061.00-1062.00] поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, и [1062.00-1063.00] поддерживать, и поддерживать, и поддерживать, и поддерживать, и поддерживать, и
[1075.00-1088.42] И мы тут как раз-таки сейчас каких-то определенных проблем не встречаем, хотя хотели бы иметь какие-то определенные структуры, архитектуры моделей, которые могут эффективно на нас работать с кодом, об этом еще поговорим. [1088.42-1075.00]  [1091.60-NA] Но важной вещью также является возможность селф-импрува таких моделей, как отдельный просто процесс обучения на кормежке данных, собственно, для модельки, так или иначе, из-за того, что мы...
[1100.00-1107.02] данных собственно для модельки так или иначе из за того что мы можем как раз таки проводить этап [1107.02-1116.72] эволюция кода которая сгенерирует наша моделька мы можем давать фидбэк самой модели это такое у нас [1116.72-1125.08] получается бесплатный рель где модельку как раз таки можно достаточно эффективно обучить чтобы [1125.08-1100.00]  [1105.90-NA] она лишилась каких-то своих ошибок причем можно давать
[1125.00-1127.00] чтобы она лишилась каких-то своих ошибок. [1127.50-1131.48] Причем можно давать ассерты к написанию [1131.48-1136.24] либо как вручную, так и какой-то другой кодовой лампе, [1136.56-1139.34] которая выигрывает сейчас всех на бенчмарках. [1139.60-1144.18] Таким образом, достаточно быстро сходить в хорошем качестве для моделей. [1147.80-1150.74] У нас может быть много связанных рисков, [1151.00-1152.54] связанных с обучением модели, [1153.12-1125.00]  [1126.90-NA] потому что
[1150.00-1157.96] рисков связанных с обучением модели потому что зачастую в любых про скрапленных данных даже в [1157.96-1164.62] стеке 2 встречаются какие-то куски кода которые могут быть связаны с лицензией а это нарушение [1164.62-1172.84] каких-то авторских прав достаточно много всяких маловаров то есть там вирусов либо какой-то [1172.84-1150.00]  [1157.14-NA] Это нехороший ход, который мог быть даже выложен в рамках просто...
[1175.00-1183.10] ход который мог быть даже выложен в рамках просто ознакомительных внутри там гитхаба в качестве там [1183.10-1189.70] учебного материала и так далее которые так или иначе может привести к тому что там помощник [1189.70-1197.18] там разработчика на его же мощностях может запустить какой-то вирус такие истории наверное [1197.18-1175.00]  [1177.88-1178.56] есть, я точно не знаю, но риск точно имеется. [1182.74-NA] Можно потерять какие-то или слить.
[1200.00-1209.66] Можно потерять какие-то или слить, по крайней мере, данные. В кусках кода нередко, как минимум, [1209.66-1218.36] находятся какие-то сниппеты или примеры, которые могут содержаться в комментариях. Тех или иных [1218.36-1224.80] персональных данных зачастую тоже может являться большой проблемой. Мы должны уметь фильтровать [1224.80-1200.00]  [1205.18-NA] такие куски хода, плюс весь код, который так...
[1225.00-1232.62] куски хода плюс весь код который так или иначе пошел обучение не факт что является очень [1232.62-1238.50] эффективным и таким образом у нас появляется проблема связанная с тем что у нас в лампка [1238.50-1244.62] может научиться на неэффективных куска хода эта история опять же у нас должна фикситься либо [1244.62-1249.06] какой-то другой более мощные лампы который будет проверять есть код который у нас при тренинге [1249.06-1225.00]  [1226.92-1230.44] находятся, но это дорого. Либо изначально мы должны иметь требования к тем [1230.44-1231.44] кускам кода, которые мы должны иметь.
[1250.00-1256.30] либо изначально мы должны иметь требования к тем кускам кода, которые мы должны будем рисовывать [1256.30-1266.18] в притрейн. Да, множество всего, короче, может быть в целом связано с рисками, начиная от каких-то [1266.18-1271.54] плохих, которые могут привести к нашим каким-то галлюцинациям или нежелательным потерям, заканчивая [1271.54-1277.96] какой-то легальной историей. Что касается бичмарков, из-за того, что мы эффективно умеем генерировать [1277.96-1250.00]  [1252.06-NA] в целом куске кода, у нас тут проблем вообще нет.
[1275.00-1302.12] Из-за того, что мы эффективно умеем генерировать в целом куски кода, у нас тут проблем вообще никаких нет. Бенчмаркам завались. Единственное, что на текущий момент, наверное, плохо, то, что нет сложных бенчмарков, потому что на текущий момент не то чтобы все решения, несмотря на то, что у них кода достаточно много, не умеют в сложной задаче, связанной с кодингом. Об этом тоже обсудим. [1302.12-1275.00]  [1277.88-NA] И, наверное, из всех...
[1300.00-1307.34] кодинга в этом тоже обсудим и наверное из всех бичмарков даже которые сейчас здесь перечислены [1307.34-1314.04] и которые развиваются даже на текущий момент там самого оптимальным самым лучшим решением является [1314.04-1321.42] просто посмотреть как на битком пенча у нас какая у нас там метрика посмотреть может быть какие-то [1321.42-1327.76] более специфичные истории типа если мы хотим помочь когда циентист обучить 1дс тысячу если [1327.76-1300.00]  [1302.22-1303.22] Если мы хотим, чтобы у нас там много языков знало, то, конечно, мы можем. [1303.22-1304.22] Мы можем сделать это, но мы не можем сделать это, [1304.22-1305.22] потому что это не так просто. [1305.22-1306.22] Мы можем сделать это, но мы не можем сделать это, [1306.22-1307.22] потому что это не так просто. [1307.22-1308.22] Мы можем сделать это, но мы не можем сделать это, [1308.22-1309.22] потому что это не так просто. [1309.22-1310.22] Мы можем сделать это, но мы не можем сделать это, [1310.22-1311.22] потому что это не так просто. [1311.22-1312.22] Мы можем сделать это, но мы не можем сделать это, [1312.22-1313.22] потому что это не так просто. [1313.22-1314.22] Мы можем сделать это, но мы не можем сделать это, [1314.22-1315.22] потому что это не так просто. [1315.22-1316.22] Мы можем сделать это, но мы не можем сделать это, [1316.22-1317.22] потому что это не так просто. [1317.22-1318.22] Мы можем сделать это, но мы не можем сделать это, [1318.22-1319.22] потому что это не так просто. [1319.22-1320.22] Мы можем сделать это, но мы не можем сделать это, [1320.22-1321.22] потому что это не так просто. [1321.22-1322.22] Мы можем сделать это, но мы не можем сделать это,
[1325.00-1331.00] обучить тот на ds-1000 если мы хотим чтобы у нас там много языков знала то что-то еще проверить [1331.00-1337.86] типа мультилингах и уменовал ну да сконцентрироваться на каких-то локальных проверках и какой какой-то [1337.86-1344.24] общий бенчмарк вообще в целом среди всех моделей взять то за основу там биткотт бенч руки у нас [1344.24-1350.68] поросли на самом деле всех бенчмарков начиная с как раз таки human ивала который вышел достаточно [1350.68-1325.00]  [1329.22-NA] давно, где-то 4 года назад, по-моему, его сделали.
[1350.00-1357.82] вышел достаточно давно, где-то четыре года назад, по-моему, его сделали как раз-таки ребята из OpenAE. [1359.14-1360.72] Задача достаточно простая. [1361.02-1364.82] У нас есть какой-то код, чаще всего это просто функция, [1365.32-1370.68] причем внутри функции описан док-стрингом примерно, как это должно выглядеть, [1370.68-1376.50] либо данные куски кода других функций, может быть, даже законченных, [1376.66-1379.54] либо внутри самой функции уже несколько строк реализовано. [1379.92-1350.00]  [1350.44-NA] за то, что мы не можем нести в мире.
[1375.00-1379.50] может быть даже законченных, либо внутри самой функции уже несколько строк реализована. [1379.92-1383.54] Задача бенчмарка достаточно простая — продолжить код. [1384.88-1388.92] По какому-то определенному контексту связаны там либо с этой функцией, [1389.04-1390.60] либо с несколькими функциями одновременно. [1391.88-1394.60] И на основании того кода, который, собственно, сгенерится, [1395.08-1398.70] строится метрика под названием там path, это что-то там. [1400.24-1375.00]  [1381.30-NA] В зависимости от того, за какое количество денег
[1400.00-1406.44] В зависимости от того, за какое количество попыток нас устроит, [1406.94-1414.84] что наша какая-то лампка пройдет тот или иной тест. [1415.94-1421.44] Здесь мы хотим как раз-таки учитывать вариативность нашей лампки. [1421.64-1424.20] Желательно, конечно, смотреть на метрику Passed-1. [1424.64-1428.22] То есть нас интересует первая генерация, и она должна быть суперидеальной. [1428.22-1400.00]  [1401.78-NA] но иногда смотрят
[1425.00-1431.42] интересует первая генерация и она должна быть супер идеальный но иногда смотрит и пасы т.н. обычно [1431.42-1441.02] пасы т.п. то есть мы в целом допускаем что часть там генерации может быть плохая но у нас интересует [1441.02-1449.66] хотя бы чтобы в один раз из пяти было хорошо вот понятное дело что там бичмарком сейчас особо [1449.66-1425.00]  [1426.62-1430.34] сильно не следят. Не так давно там сам Humanival под названием Codeval.
[1450.00-1458.04] следят не так давно там сам humanовал под названием кодовал был адаптирован для русского языка поэтому [1458.04-1465.18] сейчас в россии у нас за этим следят но сейчас бичмарк сам по себе устарел на нем выбиваются [1465.18-1470.36] какие-то уже невероятные значения плюсом бичмарк особо не обновляется то есть там как джипе тишка [1470.36-1477.18] точнее какая-то там агентура на джипе тишка она победила в этом бичмарке так там сейчас только [1477.18-1450.00]  [1452.50-NA] пока ни Gbt, ни в целом такой бенчмарк особо не смотрят.
[1475.00-1477.90] победила в этом бичмарке, так там сейчас только одни GPT, [1478.00-1479.70] в целом такой бичмарк особо не смотрят. [1480.78-1487.12] В отличие от бигкот-бенча, который является таким наследником [1487.12-1490.56] Humanvala, они об этом напрямую пишут в своей статье, [1490.98-1493.82] вот как раз-таки бигкот-бенч является достаточно интересным [1493.82-1498.88] и достаточно сложным бичмарком, причем есть сразу несколько версий, [1498.88-1503.42] как и просто фулл бигкот-бенч, так и хард бигкот-бенч. [1503.96-1475.00]  [1476.58-NA] Метрики на нем присутствуют.
[1500.00-1508.10] full биткотт бенч так и hard биткотт бенч метрики на нем пока что даже у самых классных моделей они [1508.10-1513.26] не сильно большие это не может не радовать значит есть куда расти и значит задачи действительно [1513.26-1521.60] сложные суть такого бенча заключается в том что у нас опять же есть какая-то функция нам эту функцию [1521.60-1528.94] как-то закончить но при этом все наши докстринги они оформлены определенным образом есть какие-то [1528.94-1500.00]  [1503.00-NA] параметры
[1525.00-1533.26] оформлены определенным образом, есть какие-то параметры, которые тоже важно и правильно как-то задать, [1533.38-1538.36] либо прочитать с другого контекста, к примеру, с наших импортов, что это за параметры вообще могут быть. [1539.00-1542.72] Нам надо что-то вернуть, какую-то ошибку, возможно, поднять. [1543.18-1549.52] У нас есть определенные, да, реквайрменты, мы можем немножко зафишотить нашу всю историю. [1549.52-1525.00]  [1530.48-NA] Ну и естественно как-то это все дело проверить с какими-то...
[1550.00-1557.16] Ну и, естественно, как-то это все дело проверить какими-то как раз таки ассертами, которые мы делаем. [1557.98-1566.24] Причем все примеры, которые в биткот-бенче так или иначе находятся, они верифицируются трехэтапно. [1567.14-1572.36] Изначально генерируются вообще все эти примеры с помощью каких-то методов, связанных с генерацией кода. [1572.36-1550.00]  [1557.64-NA] Затем все это дело перепрогоняется как людьми, так и какими-то более мощными моделями.
[1575.00-1577.78] как людьми, так и [1577.78-1580.10] там какими-то более мощными моделями. [1580.58-1582.06] И затем еще раз [1582.06-1583.68] дополнительная проверка с помощью [1583.68-1586.10] каких-то экспертов в [1586.10-1588.06] области программирования, какие-то кросс-чеки. [1589.64-1590.26] Ну, так или иначе, [1590.34-1592.00] да, под людьми [1592.00-1593.84] все курировано, так что там какие-то [1593.84-1596.02] суперидеальные примеры. Таких примеров [1596.02-1597.90] может быть не очень много, 1140 [1597.90-1599.90] всего, однако они хорошо [1599.90-1601.56] разбиты по доменам, они [1601.56-1603.70] задействуют так или иначе большинство [1603.70-1575.00]  [1576.30-NA] библиотек, которые
[1600.00-1606.18] разбиты по доменам, они задействуют так или иначе большинство библиотек, которые завязаны на [1606.18-1613.92] измерениях, ну, завязаны на деятельность, там, разработчиков, и с чем они чаще всего встречаются. [1613.92-1622.56] Однако, как вы могли заметить, все это дело только на питоне на текущий момент. По-моему, [1622.56-1629.34] да. Да, если я не ошибаюсь, это пока что только питон. Другие языки, сейчас даже посмотрим, [1629.34-1600.00]  [1601.00-1602.00] Он был в пустыне, и он не мог спать. Он не мог спать. [1602.00-1603.00] Он не мог спать. [1603.00-1604.00] Он не мог спать. [1604.00-1605.00] Он не мог спать. [1605.00-1606.00] Он не мог спать. [1606.00-1607.00] Он не мог спать. [1607.00-1608.00] Он не мог спать. [1608.00-1609.00] Он не мог спать. [1609.00-1610.00] Он не мог спать. [1610.00-1611.00] Он не мог спать. [1611.00-1612.00] Он не мог спать. [1612.00-1613.00] Он не мог спать. [1613.00-1614.00] Он не мог спать. [1614.00-1615.00] Он не мог спать. [1615.00-1616.00] Он не мог спать. [1616.00-1617.00] Он не мог спать. [1617.00-1618.00] Он не мог спать. [1618.00-1619.00] Он не мог спать. [1619.00-1620.00] Он не мог спать. [1620.00-1621.00] Он не мог спать. [1621.00-1622.00] Он не мог спать. [1622.00-1623.00] Он не мог спать. [1623.00-1624.00] Он не мог спать. [1624.00-1625.00] Он не мог спать. [1625.00-1626.00] Он не мог спать. [1626.00-1627.00] Он не мог спать. [1627.00-1628.00] Он не мог спать. [1628.00-1629.00] Он не мог спать.
[1625.00-1636.34] что только питон другие языки и даже посмотрим по моему где-то тут есть да да он только на питоне [1636.34-1643.18] это огорчает потому что зачастую мы хотим от помощника разработчика чтобы она мне только [1643.18-1648.02] на питоне помогал однако на текущий момент это действительно сам лучший бенчмарк хотя [1648.02-1625.00]  [1631.94-NA] Хотя трехэтапный ступенчатый какой-то анализ тех тасок, он дорогой.
[1650.00-1658.76] ступенчатый какой-то анализ тех таз и кону дорогой и только адаптируется на текущий момент под какие-то [1658.76-1667.70] другие языки ds1000 тоже очень похожий пример связанный с уже непосредственно работой там [1667.70-1677.38] датсайентистов у нас тоже есть какое-то описание возможно дата-фреймов там в пандасе и задачи и мы [1677.38-1650.00]  [1652.40-NA] мы должны на основании как раз-таки этой задачи заняться.
[1675.00-1685.54] И мы должны на основании как раз-таки этой задачи заняться генерацией кода на основании какого-то кодового контекста и привести какое-то решение. [1685.84-1689.32] И в дальнейшем его как-то засертить, что-то провести. [1691.32-1693.12] Останавливаться особо сильно на нем не буду. [1693.46-1700.16] В нем достаточно представимость данных по всем библиотекам, так или иначе, которые используют дата-сиентисты. [1700.16-1675.00]  [1678.78-1679.84] Ну и, да, современные, собственно, модели, которые там побивают всё это, естественно, GPT-чувствуют.
[1700.00-1707.30] Ну и, да, современные, собственно, модели, которые там побивают все это, естественно, GPT-Cho, Cloud, DeepSeq. [1707.86-1709.78] В целом ничего удивительного тут нет. [1711.58-1715.06] Также хорошим примером бенчмарка является SVE-бенч. [1715.36-1722.62] Он тоже зачастую, очень часто используется при скорингах всех моделей, которые так или иначе связаны с кодом. [1723.10-1700.00]  [1707.26-NA] бенч является достаточно уникальным интересным ввиду того что он решает задачу может ли какие-то
[1725.00-1733.76] интересным ввиду того что он решает задачу может ли какие-то ломки достаточно хорошо справляться [1733.76-1744.18] с закрытием и шли с на гитхабе так у нас есть какие-то примеры и шьюз пропоршн и с самими [1744.18-1753.02] там разработчиками этого бенчмарка там порядка 90 тысяч пиаров было проанализировано так или [1753.02-1725.00]  [1728.98-NA] иначе и шесть ним были все просто
[1750.00-1753.50] 90 тысяч пиаров было проанализировано так или иначе, [1753.94-1755.50] иши с ним были все просмотрены, [1756.02-1758.68] иши обычно идут с какими-то кусками кода, [1759.36-1763.50] и мы должны на основании как раз-таки всех данных, [1763.54-1766.26] которые приведены в том или ином иши, [1766.66-1771.08] сгенерировать либо код, который сможет помочь решить это ишью, [1771.08-1773.60] и потом, собственно, сгенерировать тесты, [1773.70-1775.60] точнее, провести тесты под него, [1776.10-1750.00]  [1754.40-NA] потому что в этом бенчмарке они заранее все известны.
[1775.00-1784.84] под него потому что на в этом бенчмарке они заранее все известны ну вот да ты ими должны сгенерировать [1784.84-1794.40] решение это конец вот на этом бенчмарке тоже не особо большие какие-то результаты и достаточно [1794.40-1802.48] затюнены как будто бы только подход модели но выбиваются вперед то есть там не встретишь просто [1802.48-1775.00]  [1779.40-NA] как там не знаю в ds1000 джипить
[1800.00-1806.54] то есть там не встретишь просто как там не знаю в дэс тысячи джипе течет клауд нет тут встреч [1806.54-1815.66] конкретно какие-то вещи типа у дикта которые как-то запромтировали клад там и свои агент [1815.66-1823.20] опять же на клауде что-то связанное с чепики я не знаю название этого приложения так или иначе вот [1823.20-1827.78] то есть созданы там людьми специальный промпт какой-то какая-то инструкция которая позволяет [1827.78-1800.00]  [1802.18-NA] хорошо с этим печем как-то справляются.
[1825.00-1830.34] промпт какой-то какая-то инструкция которая позволяет хорошо с этим печем как-то справляться [1830.34-1838.02] можно профильтровать внутри самого бенчмарка найти там непосредственно просто какие-то модельки но [1838.02-1842.94] хотел показать именно вот это плюс метрики не особо сильно там опять же большие что говорит [1842.94-1848.70] о сложности такого бенчмарка но это бенчмарк крайне полезен потому что мы хотим видеть дальнейшем от [1848.70-1825.00]  [1831.12-NA] наших там кодовых помощников именно такой пример использовали.
[1850.00-1854.88] помощников именно такой пример использования. [1857.54-1860.02] Да, на бичмарках по коду все. [1862.12-1869.10] Мы хотим в целом в будущем от подобных помощников добиться как раз-таки генерации сложного кода. [1869.44-1872.12] Мультилайн это в целом уже достаточно сложная история. [1872.54-1876.70] Это не просто закончить предложение, это еще и как-то продолжить его, [1876.70-1850.00]  [1853.30-NA] написать несколько строчек кода, но мы хотим, чтобы такие помошники...
[1875.00-1878.26] как-то продолжить его, написать несколько строчек кода, [1878.42-1880.82] но мы хотим, чтобы такие помощники думали куда дальше, [1882.22-1887.18] возможно, написали как и целый скрипт, который поможет решить проблему внутри какого-то кода, [1887.52-1890.28] либо как-то оптимизирует целую библиотеку, [1891.30-1895.26] либо вообще сгенерирует целое репо под какую-то задачу, [1896.62-1899.46] которую можно будет из коробки запускать. [1899.46-1904.64] Пока таких решений, к сожалению, на рынке либо крайне мало, и они неэффективны, [1904.82-1875.00]  [1875.36-NA] от людей, которые не могут работать.
[1900.00-1906.14] таких решений, к сожалению, на рынке либо крайне малы, и они неэффективны, либо вообще в целом нет. [1907.30-1910.94] Мы хотим изобрести, естественно, специальную архитектуру, адаптированную под код, [1911.20-1915.68] ровно такую же, как мы это видели, к примеру, в модальности по видео, [1915.84-1921.30] когда мы делали какой-то проектор на токены, естественно, нового языка, [1921.56-1926.36] тот же проектор, к примеру, для кода, в целом, возможно, был бы хорошей идеей, [1926.36-1928.68] я таких исследований еще не видел и не находил.
[1925.00-1928.66] был хорошей идеей, я таких исследований еще не видел и не находил. [1929.68-1936.22] Возможно, мы хотим более умный способ работы с данными, [1936.82-1942.80] иметь связанных с кодом, как-то лучше использовать какой-то фильтринг, [1943.60-1948.10] понимать, какой код у нас может нести действительно большую ценность [1948.10-1950.30] для обучения модели. [1951.10-1925.00]  [1929.70-NA] В этом году мы хотим изобрести крутые бенчмарки, связанные
[1950.00-1951.90] модели. [1951.90-1955.24] Мы хотим изобрести крутые бенчмарки, связанные с [1955.24-1959.16] код-геном, потому что все текущие бенчмарки, они так [1959.16-1963.66] или иначе связаны на достаточно простые проблемы для текущих [1963.66-1966.16] помощников. [1966.16-1969.74] Помимо колд-бенча, там, SVE-бенча, мало что суперсложного [1969.74-1971.88] можно найти. [1971.88-1975.00] Мы хотим поддержку иметь не только там Python как языка, [1975.00-1979.42] мы хотим вообще в целом все языки, в том числе и низкоуровневые, [1979.42-1950.00]  [1950.58-NA] представляют.
[1975.00-1978.46] хотим вообще в целом все языки, в том числе низкоуровневые, [1978.88-1984.26] которые представляются в текущем там ландшафте, [1984.72-1988.96] очень редко, очень мало, но так или иначе, [1989.08-1992.34] как будто бы лампка умеет ходить в грамматике, [1992.34-1997.50] поэтому why not, почему бы не обучить там какие-то сложные, тяжелые языки, [1997.62-2000.22] почему бы не синтезировать там данные, [2000.64-1975.00]  [1979.64-NA] которые могут быть для подобного иската.
[2000.00-2009.36] которые могут быть для подобного языка релевантны. Мы хотим, естественно, иметь поддержку continuous [2009.36-2016.66] learning. Тут это супер сильно важно. Напоминаю, что такое это, когда мы продолжаем обучаться, [2016.66-2023.82] даже после тренинга, какой-то нашей очередной модельке. Мы хотим понимать, какие кодовые [2023.82-2028.74] фреймворки сейчас актуальны, что нам нужно сейчас обязательно, чтобы наша модель умела, [2028.74-2000.00]  [2001.26-NA] было, чтобы она была в порядке.
[2025.00-2031.30] что нам нужно сейчас обязательно чтобы наши модель умела чтобы она подстраивалась под текущие какие-то [2031.30-2041.18] обстоятельства к примеру там не знаю выходит новая там статья про какую-то там оптимизацию и мы хотим [2041.18-2046.24] естественно чтобы есть она революционная была то наш там универсальный помощник поддерживал подобный [2046.24-2054.94] алгоритм которые были бы реализованы в этом новом алгоритм ну да естественно хотим решить проблему [2054.94-2025.00]  [2054.98-NA] Благодарю вас за внимание.
[2050.00-2055.50] Ну да, естественно, хотим решить проблемы, связанные [2055.50-2056.50] с безопасностью. [2056.50-2061.66] На каком-то уровне такие ломки должны понимать, [2061.66-2064.52] где у нас находится там опасный код, где у нас находится [2064.52-2069.24] неопасный код, причем как-то предупреждать об этом пользователя, [2069.24-2071.86] предупреждать пользователь о возможных каких-то авторских [2071.86-2077.24] правах, либо об утечке данных, и как-то нивелировать это. [2077.24-2050.00]  [2052.96-NA] Это тоже будущий вызов, пока, естественно, не будет.
[2075.00-2080.92] И как-то нивелировать это, это тоже будущий вызов, пока естественное решение особо нет. [2082.42-2084.34] Теперь поговорим про аудио. [2085.02-2087.36] Олег, а можно вопрос про кодовую модальность? [2088.04-2092.54] У моделей будет такое же свойство, например, если, ну вот, когда обучают LLM, [2092.74-2096.38] большая часть данных на английском языке, добавляют немного языков, [2096.38-2098.36] например, русский, китайский. [2099.02-2103.00] И модель начинает с меньшим количеством данных понимать уже другие языки. [2103.18-2075.00]  [2077.00-NA] И такое же свойство есть на данном примере.
[2100.00-2105.42] с меньшим количеством данных понимает уже другие языки такое же свойство есть на там например весь [2105.42-2112.88] код на питоне практически весь да и то есть мы к примеру какую-то питоновскую чисто модель засунем [2112.88-2121.00] код связанный там си плюс плюс нам возможно выдастся код носит плюс плюс но возможно он [2121.00-2127.16] будет нерабочий объясняю вообще почему такое явление вдруг может произойти на самом деле [2127.16-2100.00]  [2104.50-NA] все данные которые вот тут были рассмотрены
[2125.00-2137.26] На самом деле, все данные, которые вот тут были рассмотрены на самом первом слайде, они и так или иначе используются в притринах, но при этом, почему у них такой большой размер? [2137.78-2152.00] Не всегда это код. Во время процесса дедупликации порой мы фильтрируем все комментарии, однако чаще всего, даже при разработке гигакода нашего российского, мы эти комментарии все оставляем. [2152.94-2125.00]  [2128.00-NA] В комментариях у нас находится...
[2150.00-2156.30] российского мы эти комментарии все оставляем комментариях у нас находится куча интересной [2156.30-2160.38] информации которая связана во первых с другими какими-то языками программирования зачастую [2160.38-2165.42] потому что вставляют примеру докстринговый сниппет там кода на си плюс плюс перепишет [2165.42-2172.60] на питон что не подобное так и в целом комментарии несут очень много технической информации которые [2172.60-2178.62] содержат как русский язык то китайский язык как такой английский какие-то такие большие [2178.62-2150.00]  [2151.38-NA] большие представленности.
[2175.00-2177.70] китайский язык, как такой английский, [2177.84-2179.56] какие-то такие большие представленности. [2180.94-2181.50] Поэтому [2181.50-2184.12] представленность языков, [2184.18-2185.66] она так или иначе есть, [2185.86-2187.68] даже, блин, вот жалко ее не привел [2187.68-2188.18] на стеки. [2189.66-2191.58] Она достаточно большая, [2191.76-2194.04] и все в целом про нее шарят, [2194.10-2195.30] но в основном, конечно, питон, [2195.76-2198.02] но несмотря на то, что представимость [2198.02-2199.98] там, к примеру, там какого-нибудь [2199.98-2202.24] Котлина, может быть, [2202.28-2203.70] там 6% от всего, [2203.90-2175.00]  [2176.30-NA] отходно от всех данных для обучения.
[2200.00-2205.24] Kotlin, может быть, там 6% от всего, от всех данных для обучения, [2205.44-2211.86] но все равно у нас ломки достаточно хорошо запоминают подобные данные [2211.86-2216.88] и могут спокойно потом генерировать данные, там, с Kotlin связанные, [2217.22-2219.80] даже несмотря на то, что там достаточно мало было примеров. [2220.20-2223.68] Единственное, что проблема будет это хорошо как-то грамотно протестировать. [2224.04-2227.84] У нас из всех бенчмарков, которые вообще в целом есть там для кода, [2227.94-2200.00]  [2202.14-NA] у нас только парочка связанных
[2225.00-2231.90] бенчмарков, которые вообще в целом есть там для кода, у нас только парочка связанных с мультилингл [2231.90-2239.64] историей. Так у нас есть только мультилингл human-to-vile, но human-to-vile как бенчмарк, он не слишком [2239.64-2246.48] сложный, поэтому нам тяжело будет сказать, насколько хорошо там наша моделька справляется с этим. [2246.48-2254.76] Вот, но если мы там разработаем какие-то определенные наши тесты, которые там нам нужны для [2254.76-2225.00]  [2225.24-NA] для проведения общей работы.
[2250.00-2252.82] Но если мы там разработаем какие-то определенные наши тесты, [2252.92-2257.98] которые нам нужны для проверки эффективности работы на том или ином языке, [2258.46-2260.00] нам, возможно, этого будет достаточно. [2261.20-2263.36] Нужно ждать появления каких-то новых бенчмарков, [2263.50-2268.58] которые нам помогут рассказать, типа, мультилингву, бигконд-бенч, [2268.58-2271.58] к примеру, о качествах подобных моделей, [2272.26-2273.98] которые будут ориентированы не только на Python, [2275.44-2276.94] и было бы вообще суперславно, [2277.16-2279.40] а так, в целом, все современные помощники, [2279.60-2250.00]  [2252.58-NA] они
[2275.00-2280.32] было бы вообще суперславно а так в целом все современные там помощники они так или иначе [2280.32-2288.50] поддерживают практически все языки программирования как и любая в целом была ламка какую не спроси все [2288.50-2294.08] в целом там на каких-то даже около мертвых языках умен говорить но понят делаем с не самым большим [2294.08-2304.94] качеством того ч как-то развернуто ответил надеюсь ответил да спасибо да супер да давайте говорим про [2304.94-2275.00]  [2304.98-NA] По-прежнему, это не только для нас, но и для всех нас.
[2300.00-2301.42] ответил. Да, спасибо. [2302.24-2303.98] Да, супер. Да, давайте [2303.98-2306.14] говорим про модальность аудио. [2307.24-2307.88] Честно, [2309.02-2310.04] это как [2310.04-2311.78] одновременно достаточно простая тема, [2311.84-2313.94] так и крольче нора, [2314.74-2316.36] ввиду того, что зачастую [2316.36-2317.74] мы от аудиомоделек [2317.74-2319.82] не хотим добиваться того, что мы [2319.82-2322.10] просто положили какое-то [2322.10-2324.28] текстовое описание, наш какой-то [2324.28-2326.20] аудиоинпут, и нам [2326.20-2328.26] на выходе получился просто какой-то текст [2328.26-2300.00]  [2301.74-NA] импорт, а зачастую мы хотим, чтобы мы могли использовать
[2325.00-2331.00] и нам на выходе получился просто какой-то текст и input зачастую мы хотим вот самую последнюю [2331.00-2338.26] историю которые реализованы на картинке это аудио input и текст prompting и на выходе мы получаем [2338.26-2344.20] зачастую нам даже текст аутпут не нужен мы хотим тоже получить аудио но про это рассказывать можно [2344.20-2350.50] очень долго там много подходов по большей части сегодня сосредоточить просто на аудио как модальности [2350.50-2325.00]  [2327.76-2329.50] То есть мы добавляем, к примеру, какое-то аудио на вход, мы добавляем текст и получаем темноту.
[2350.00-2352.02] модальности, то есть мы добавляем, к примеру, [2352.08-2354.04] какое-то аудио на вход, мы добавляем текст [2354.04-2355.28] и получаем там текст [2355.28-2356.58] на выход. [2358.14-2360.04] Добавление там вукодеров несет [2360.04-2362.04] определенные и [2362.04-2364.20] какие-то добавочные применения [2364.20-2366.00] похожих модальностей. К примеру, мы [2366.00-2367.94] можем генерировать музыку [2367.94-2370.00] достаточно эффективно, причем [2370.00-2372.02] неплохо делают это современные модели, [2374.28-2376.02] но в основном мы хотим [2376.02-2379.50] просуммаризировать какое-то видео,
[2375.00-2383.82] хотим просуммаризировать какое-то видео к примеру на ютюбе по аудио транскрипции здесь как раз нам [2383.82-2392.58] помогают там спич плюс текст это текст истории вот что там нужно нам как-то поменять но на самом [2392.58-2398.46] деле я не стал сильно растягивать историю связан с этой модельностью ровно почему потому что она [2398.46-2375.00]  [2380.86-NA] сильно не отличается от вижен истории от слова совсем мы единственное что подменяем это
[2400.00-2408.10] от вижен истории от слова совсем мы единственное что подменяем это какой-то visual энкодер на [2408.10-2417.04] аудио энкодер и в целом все готово у нас есть одна небольшая проблема она знакома тем кто занимался [2417.04-2426.10] там как раз таки аудио моделями у нас у токенов аудио токенов сильно выше значение беден гав чем [2426.10-2400.00]  [2401.42-2402.48] у текстовых токенов. [2403.92-2404.64] Это связано там со многими проблемами, которые
[2425.00-2432.20] беден гав чем у текстовых токенов это связано там со многими причинами так или иначе и для [2432.20-2438.80] того чтобы нам когда мы делаем нашу там прожектор который нам будет это все вот одно как раз это [2438.80-2446.88] фаза ванная там пространство пихать нам необходимо и токи нормализовать и в целом но нормализация [2446.88-2454.10] это там не то чтобы какой-то супер интересный процесс про это на и можно найти тысячи тысяч [2454.10-2425.00]  [2425.88-NA] обновить.
[2450.00-2456.66] суперинтересный процесс, про это можно найти тысячи и тысячи, одну реализацию и статью в [2456.66-2463.86] интернете, поэтому тут тоже говорить об этом сильно не буду. Мы достаточно эффективно умеем это делать, [2464.14-2472.12] единственное, что об этом нужно знать, что там как раз-таки в нашем, когда мы подаем все в фьюзированный [2472.12-2478.10] там embedding space, у нас могут быть разные значения там у аудиотокенов и текст-токенов, а желательно, [2478.10-2450.00]  [2451.56-NA] чтобы они были равно распределены.
[2475.00-2479.52] значения там у аудио токенов и текст токенов желательно чтобы они были равно распределены [2479.52-2487.30] потому что это все-таки должно слиться в какую-то одну интер лифт информацию когда мы должны [2487.30-2492.88] учитывать и то и другое одновременно и правильно так чтобы у нас там не было переобучение какой-то [2492.88-2502.56] из вот этих двух историй в плане бенчмаркирования люди сделали все очень просто на самом деле мы [2502.56-2475.00]  [2477.44-NA] Мы проверяем любую модель, которая так или иначе сотрудничает.
[2500.00-2505.70] очень просто на самом деле мы проверяем любую модель который так или иначе затрагивает у нас [2505.70-2516.00] аудио input как обычно текстовую модель аудио input порой тестируем отдельно просто за инструктив [2516.00-2525.78] модель на задачу автоматик спички к внешне то есть у нас есть какая-то голосовое там сообщение [2525.78-2500.00]  [2504.22-NA] Который мы подаем модель, мы промтим ее, чтобы она
[2525.00-2532.26] сообщение, которым мы подаем модель, мы промтим ее, чтобы она написала нам транскрипцию этого звука, [2532.26-2540.36] модель выдает транскрипцию звука, и мы меряем по всем тем же как раз таки методам, которые современные [2540.36-2547.44] люди там меряют, automatic speech recognition сервиса. Основной метрикой во всех этих сервисах [2547.44-2525.00]  [2532.50-NA] является там борд р рейд есть модификации там чартер р рейд есть сентенсер рейд и так далее так
[2550.00-2558.12] модификации, там, character rate, есть sentence rate, и так далее, и так далее, но в основном вер, вер мерится [2558.12-2564.86] просто как количество замен, количество вставок и количество удаления тех или иных символов на [2564.86-2570.64] общее число символов в оригинальном как раз таки сообщении, то есть у нас есть, к примеру, вот [2570.64-2578.48] оригинал, у нас слово, и дата, и транскрипция, у нас слово quick поменялось на brown, а точнее [2578.48-2550.00]  [2551.50-NA] Квик вообще убралось, осталось только выключить.
[2575.00-2581.64] quick поменялось на браун, а точнее quick вообще убралось, осталось только браун, и lazy dog там [2581.64-2590.98] добавилось. Пример какое-то слово могло там неправильно как-то транскрибироваться, да, и мы посчитаем [2590.98-2596.82] количество вот этих вставок там удалений и замен, разделим на общее число слов в оригинальном [2596.82-2603.66] предложении, получим значение вверх. В современных моделях оно очень хорошее, порядка трех процентов [2603.66-2575.00]  [2576.34-NA] Он.
[2600.00-2610.68] порядка трех процентов то есть в целом очень редкие какие-то ошибки и зачастую мы никак не [2610.68-2619.24] хотим учитывать аудио составляющего таких моделей потому что ошибка это маленькая это не картиночная [2619.24-2625.12] история где ошибки могут быть достаточно большие и там вообще нет какой-то определенной истины вот [2625.12-2600.00]  [2604.88-NA] Для аудио данных в аудиоэнкодерах в любом случае можно использовать
[2625.00-2631.10] Для аудио-данных в аудио-энкодерах в любом случае решили привести, [2631.28-2634.36] и конкретно для российского рынка, для нероссийского рынка, [2634.36-2637.76] можно найти где угодно и в большем количестве часов записи. [2638.44-2643.40] Основным височником данных является OpenCT на русском. [2643.66-2650.36] Там порядка 20 тысяч часов записи продиктованного текста в абсолютно различных доменах. [2651.34-2625.00]  [2629.62-NA] в обменах, это голос от Сбера.
[2650.00-2660.08] доменах это голос от сбера тоже очень очень много часов порядка 18 тысяч транскрибации [2660.08-2666.68] происходит обычно с каких-то радио эфиров потому что очень хороший источник данных для нас там [2666.68-2673.40] постоянно люди говорят поэтому давайте запишем большое количество там эфиров заставим людей там [2673.40-2650.00]  [2656.54-NA] все это транскрибировать и потом на этом сидели обучимся вам public спичей youtube
[2675.00-2677.04] и потом на этом все деле обучимся. [2677.58-2678.96] Там паблик спичей, [2679.30-2680.24] ютуба, [2681.32-2682.92] аудиокниг, звонков [2682.92-2685.12] и прочие какие-то истории. [2685.62-2686.98] И есть еще небольшой [2686.98-2687.88] LibriSpeech [2687.88-2691.06] на 98 часов записи, [2691.22-2693.16] но его зачастую используют как какую-то [2693.16-2695.38] тестовую выборку для проверки [2695.38-2697.28] навыков. Как раз просто посчитать веру. [2698.20-2699.24] Единственным исключением, [2699.24-2701.00] наверное, из правил, больше [2701.00-2703.02] бенчей вы не найдете, наш любимый [2703.02-2675.00]  [2676.96-NA] знакомый Биг Бенч, только не был в состоянии.
[2700.00-2708.44] больше бенча не найдете наш любимый и знакомый big bench только теперь с приставкой аудио тоже [2708.44-2713.98] тысячи там аудио каких-то вопросов мы хотим посмотреть на как раз таки какой-то спичи [2713.98-2721.08] лиза нинг связать аудио наше сообщение с сообщением на текстовом языке что-то померить но [2721.08-2727.38] больших отличий там от любого big bench натуральном языке на самом деле нет да тот же big bench только [2727.38-2700.00]  [2702.62-NA] только вместе с голосовыми сообщениями.
[2725.00-2730.70] деле нет на тот же big bench только вместе с голосовыми сообщениями поэтому он достаточно [2730.70-2736.22] сильно там резаный но при этом учитывается несколько задач как тексту текст так спичку [2736.22-2743.70] спич тексту спички спичку текст для моделей потому что там есть такая вот модификацию [2743.70-2750.40] там у этого бенчмарка так или иначе до закончили на самом деле с модальностями проуди больше [2750.40-2725.00]  [2728.34-NA] что углубляться не будем по прокат рассказали про vision тоже
[2750.00-2751.42] больше углубляться не будем. [2751.70-2753.84] Про код рассказали, про Vision тоже. [2756.84-2757.70] Да, теперь [2757.70-2760.04] кратко давайте расскажем, [2760.24-2761.34] как вообще в целом [2761.34-2764.08] занимаются тем, что собирают сервис на базе LLM. [2765.14-2766.06] Моделька у нас готовая [2766.06-2767.76] есть. Теперь нам необходимо [2767.76-2770.22] ее обернуть в какой-то [2770.22-2772.06] сервис, который действительно на нашем железе [2772.06-2773.42] достаточно бы эффективно работал. [2773.92-2775.54] Причем мы предъявляем сразу несколько [2775.54-2777.78] требований к нашему сервису. [2777.90-2779.06] Естественно, он должен быть быстрый.
[2775.00-2777.78] сразу несколько требований к нашему сервису. [2777.90-2779.08] Естественно, он должен быть быстрый. [2780.68-2782.90] Медленные сервисы нас не особо сильно интересуют. [2783.02-2784.24] Дожидаясь ответа «год», [2784.24-2788.52] любое физическое лицо, которое пользуется твоим сервисом, [2788.94-2789.68] просто уйдет. [2790.48-2794.24] У этого сервиса должна быть достаточно большая пропускная способность. [2795.08-2799.58] То есть мы хотим, чтобы наша скорость не сильно страдала [2799.58-2803.46] при огромном потоке пользователей [2803.46-2775.00]  [2776.46-NA] с своими запросами.
[2800.00-2806.24] огромном потоке пользователей с своими запросами в наш сервис. [2808.70-2810.60] Ну, естественно, сервис должен функционировать, [2810.68-2813.18] функционировать неправильно, без нарушения функциональности, [2813.32-2816.04] и он должен быть стабильный во времени, чтобы никогда не падал и так далее. [2816.04-2822.04] Но наши все основные требования как раз таки связаны со скоростью и с рутпутом. [2823.98-2825.00] Объясняю почему. [2826.46-2828.96] Зачастую сервисы вообще делятся на два типа. [2829.38-2800.00]  [2801.04-NA] что это тут признается.
[2825.00-2828.96] Зачастую сервисы вообще делятся на два типа. [2829.30-2832.06] Я тут презентацию не представил, поэтому голос там расскажу. [2834.26-2840.20] И у каждого есть какая-то своя метрика, которая является основной. [2840.96-2846.22] Так, к примеру, если мы делаем сервис по типу Нейра, который Яндексовская, [2847.80-2825.00]  [2833.78-NA] Мы, на самом деле, не хотим добиться от нее...
[2850.00-2862.12] как мы не хотим чтобы потому что она очень часто занимается там к примеру кем-то задачами связаны [2862.12-2868.54] просумеризируем не это видео в это самый популярный запрос там у нейро берутся какое-то видео там на [2868.54-2875.00] ютюбе мы хотим чтобы она просумеризировалась нам не суть важно тут tokens per second на [2875.00-2850.00]  [2854.20-NA] На самом деле, нам здесь очень будет важно, там как раз-таки пропускная способность.
[2875.00-2882.64] самом деле нам здесь очень будет важно там как раз таки пропускная способность то есть мы хотим чтобы [2882.64-2890.90] при очень большой нагрузки у нас наш сервис все равно стабильно работал выдавая тот же токен [2890.90-2898.94] сперсик он которым выдает в обычном режиме чтобы сильно не страдал когда в каких-то онлайн [2898.94-2875.00]  [2877.46-2877.66] ассистента, к примеру, [2879.10-2881.02] если вы там зайдете там сейчас в
[2900.00-2910.56] к примеру если вы там зайдете там сейчас в telegram да но она напишите там гига чату что-то нам тут [2910.56-2917.24] целом будет важно конечно так из персикон супер важно но нам будет важно и тайм ту ферст окин это [2917.24-2923.46] самый первый шаг для любой ломки потому что нужно заниматься контекст декодингом нужно просто этом [2923.46-2900.00]  [2905.90-NA] до какое-то время в очереди на запрос потому что там пропускная способность можно позволить
[2925.00-2931.16] очереди на запрос потому что там пропускная способность можно позволить да вы сильно [2931.16-2937.50] от таки не зация будет все это дело зависеть так из декодинг нам позволяет как раз таки ломки сначала [2937.50-2943.72] обработать ваш запрос сгенерировать на него ответ а затем уже как раз таки итеративно идти это будет [2943.72-2949.80] сильно быстрее поэтому зачастую у нас таким сперсик он как в метрике качества там работы [2949.80-2925.00]  [2930.20-NA] сервиса не учитывается порой первый токен а его отбрасывают потому что это как отдельный метод
[2950.00-2956.90] не учитывается порой первый токен его отбрасывают потому что это как отдельная метрика у нас хотя [2956.90-2963.02] можно не отбрасывать в целом тогда будут там чуть другие но очень схожи все равно значения [2963.02-2973.82] современной модельки как-то распределены на этом графике по как раз таки двум этим метриком самый [2973.82-2950.00]  [2956.12-NA] идеальный квадрант у нас очень маленькое время на time to first token.
[2975.00-2983.50] нас очень маленькое время на тайм ту ферз токен и очень большое количество токен спер секанс понятное [2983.50-2989.22] дело такого достигают обычно какие-то маленькие модельки либо моделька стамп с приставку flash [2989.22-2997.98] ну а какие-то очень мощные модели одних достаточно там мощный какой-то декоринг [2997.98-2975.00]  [2981.96-NA] происходит типа дирси дипсика у них очень большой обычно time to first окин но при этом можете
[3000.00-3012.06] У них очень большой обычно time-to-first токен, но при этом может сильно отличаться в зависимости от задач, которые ставятся перед моделькой по tokens-per-sequence. [3012.06-3000.00]  [3007.82-3008.58] В tokens-per-sequence очень важно в целом учитывать то, с чем мы работаем. [3017.92-NA] Так у нас может быть история связана с тем, что нам важно максимизировать TPS по питону, по математике.
[3025.00-3032.68] с тем, что нам важно максимизировать TPS по питону, по математике, по русскому языку или по английскому. [3032.68-3038.90] И мы можем очень быстро заметить, что токены на самом деле по разным доменам, они сильно разные. [3039.50-3040.98] Поэтому нужно обращать на это внимание. [3041.36-3048.10] Иногда производится замер по TPS сильно, как сказать, смещенный, [3048.44-3025.00]  [3031.00-NA] Ввиду того, что мы меряем TPS GPT-C и меряем...
[3050.00-3059.78] мы там меряем там тпс джипе течет и меряем тпс там не знаю код помощника как раз разработчика и мы [3059.78-3066.74] знаем что там фертильность и кинезации то есть в среднем размер токина какой-то он на коде сильно [3066.74-3075.92] выше чем на русском языке так мы можем наблюдать здесь что у нас там здесь видно средний там длина [3075.92-3050.00]  [3054.06-NA] цена токена в GPT-4 она там четыре с чем-то на русском языке?
[3075.00-3081.72] Средняя длина токена в GPT-4, она там 4 с чем-то, на русском языке это 2 и там 2. [3083.26-3089.26] То есть сгенерировать такой токен, сгенерировать другой, на самом деле требует разных скоростей вдруг. [3092.02-3098.10] И о чем очень хочется сильно поговорить, что вообще так или иначе повлияет на риски использования LLAM, [3098.10-3103.02] это промерч методы оптимизации, которые в сервисах используют. [3103.32-3075.00]  [3076.98-NA] Вдруг мы очень быстро, как будто бы, сжали все снаряды.
[3100.00-3107.68] которые в сервис используют вдруг мы очень быстро на самом деле начинает понимать что все наши [3107.68-3115.48] модели которые мы разработали безумно долгие и требует очень много памяти излишней памяти мы [3115.48-3121.50] это все можем сильно оптимизировать при этом никак не потеряв качестве зачастую оптимизации добавляя [3121.50-3127.68] самый легкий способ это просто добавить новых железяк понят дело может купить там со самые [3127.68-3100.00]  [3102.32-NA] современные видеокарточки и за
[3125.00-3131.36] понятное дело может купить там самые современные видеокарточки и забыть о нашей текущей проблеме [3131.36-3137.12] но на самом деле мы можем куда лучше мы иногда можем заменить какие-то архитектурные способности [3137.12-3145.34] модели там маешки в целом микшеров экспорта они быстрее работают чем обычные там dance [3145.34-3154.28] до нейросети но зачастую объединяют методы связанные с какими-то архитектурными решениями [3154.28-3125.00]  [3126.00-NA] внутримодными.
[3150.00-3155.22] объединяют методы, связанные с какими-то архитектурными решениями внутри моделей, [3155.84-3160.08] и железную историю, то есть оптимизация именно хардвера, [3160.72-3162.74] и скрестили это все дело в мерч-методы, [3164.34-3169.22] когда мы достаточно эффективно в тех вещах, которые мы уже давно знаем, [3169.80-3176.22] можем использовать управление виртуальной памятью, управление видеопамятью, [3176.96-3150.00]  [3153.78-NA] Видеопамятью, так что у нас в целом все начнет считаться
[3175.00-3181.84] управление там видеопамятью так что у нас целом все начнет считаться в несколько раз быстрее при [3181.84-3186.86] этом это никак не потеряет в качестве потому что мы сохраняем ровно ту же логику работы так [3186.86-3193.50] примеру самый эффективный способ вообще там по оптимизации любого лм сервисом и подробно сегодня [3193.50-3201.74] разберем таковы кэш continuous бачинг идея в нем супер просто она на картинке мне кажется даже [3201.74-3175.00]  [3176.98-3177.46] сильно объяснять как-то это не надо. [3178.26-NA] Мы хотим...
[3200.00-3206.66] на картинке и мне кажется даже сильно там объяснять как-то это не надо мы хотим когда у нас вот такой [3206.66-3212.48] вот бач при этом он там заканчивается достаточно рано мы хотим в оставшуюся часть бача потому что [3212.48-3217.28] она у нас просто западе на и вставить какой-то другой бач который был там сильно меньше всего [3217.28-3224.42] нашего сэмпла и мы таких бачей скорее всего найдем так вот к примеру там в с1 вот эту всю историю до [3224.42-3200.00]  [3205.04-NA] поместился батч S6, который состоял всего там из двух токенов условно.
[3225.00-3229.56] Вместился батч S6, который состоял всего из двух токенов условно. [3231.12-3235.84] Здесь вместился S5, который тоже из двух токенов состоял, при этом из трех. [3237.50-3239.72] Это из двух, наверное, а тут просто падинг. [3240.48-3243.98] И мы таким образом сильно скомпонуем наше пространство батчей, [3244.14-3246.88] которые мы подаем нашу ломку, и сильно быстрее посчитаем. [3247.00-3250.32] При этом мы будем очень хорошо знать, где у нас что заканчивается, [3250.32-3253.70] потому что мы специальные токены будем использовать, которые end-of-sentence являются. [3254.62-3225.00]  [3226.00-3227.00] Это флешмобильный инструмент, который позволяет пользователям внести в себя вред. [3227.00-3228.00] Это флешмобильный инструмент, который позволяет пользователям [3228.00-3229.00] внести в себя вред. [3229.00-3230.00] Это флешмобильный инструмент, который позволяет пользователям [3230.00-3231.00] внести в себя вред. [3231.00-3232.00] Это флешмобильный инструмент, который позволяет пользователям [3232.00-3233.00] внести в себя вред. [3233.00-3234.00] Это флешмобильный инструмент, который позволяет пользователям [3234.00-3235.00] внести вред. [3235.00-3236.00] Это флешмобильный инструмент, который позволяет пользователям [3236.00-3237.00] внести вред. [3237.00-3238.00] Это флешмобильный инструмент, который позволяет пользователям [3238.00-3239.00] внести вред. [3239.00-3240.00] Это флешмобильный инструмент, который позволяет пользователям [3240.00-3241.00] внести вред. [3241.00-3242.00] Это флешмобильный инструмент, который позволяет пользователям [3242.00-3243.00] внести вред.
[3250.00-3255.04] потому что мы специальные токены будем использовать которые end of sentence являются это flash [3255.04-3261.82] attention их целое семейство тоже сегодня подробно не поговорим это page detention он ничего общего [3261.82-3267.98] с словом attention вообще не имеет но подход очень интересный я отдельно статью тут оставил на эту [3267.98-3276.16] всю историю но мы смотреть на него не будем там квантизованные лоры интересные методы квантизации [3276.16-3250.00]  [3252.92-NA] лампок на int8.
[3275.00-3279.04] методы квантизации лмок на int8. [3280.76-3283.18] Это использование, там, k-bit precision, [3283.70-3289.10] для того, чтобы, там, как-то заквантить наши параметры, [3289.22-3290.78] при этом не сильно поменять в качестве. [3291.36-3293.08] Я, кстати, наверное, отдельную скину, [3293.44-3294.94] сегодня тоже на смотреть на это не будем. [3295.62-3296.72] Фьюзирование слоев. [3296.72-3299.80] Это больше архитектурная, конечно, история, нежели чем мерч. [3299.98-3302.60] Но зачастую это используется, [3302.80-3275.00]  [3279.32-NA] когда несколько слоев у нас просто помощи
[3300.00-3306.24] но зачастую это используется, когда несколько слоев у нас просто по мощности обвиняются условно в один, [3306.46-3307.58] и быстрее считаться начинает. [3308.06-3312.68] И есть целые фреймворки для оптимизации, это там Petals и Swarm, [3313.40-3316.10] но давайте начнем с Flash Attention. [3316.88-3319.22] Здесь не сильно устали, но не так много осталось. [3322.70-3325.86] Нет, это тот бач, который мы подаем на вход, а ла-лам. [3327.18-3300.00]  [3304.14-NA] Поэтому мы тут просто определенным образом...
[3325.00-3332.86] на вход и лалом поэтому мы тут просто определенным образом синие то паттинги насколько понимаю либо [3332.86-3339.22] какие-то специальные токены красные это end of sentence там желтые это собственно те данные [3339.22-3347.94] которые мы хотим подать просто это как пример компоновки бача когда мы вместо там весь у нас [3347.94-3325.00]  [3332.02-NA] к примеру весь наш вся наш весь наш бач зак
[3350.00-3358.44] Весь наш батч заканчивается, к примеру, на S6, то есть шестое там предложение. [3358.44-3362.60] Мы укомпоновали, на самом деле, всего в четыре, хотя их было изначально шесть, [3362.60-3365.88] просто было очень много паддингов, пробелов, которые нам особо не нужны, [3365.88-3370.34] и мы это все дело скомпоновали, continuous patching здесь хорошо работает. [3372.10-3350.00]  [3355.46-3359.66] Начнем с Flash Attention. Это такая супер база для всех LLM.
[3375.00-3382.32] Это такая супер база для всех LLM-ок, сервисов и так далее, которые используются. [3382.32-3391.24] Она по своим результатам в целом сильно меняет тренинг тайм, она меняет инференс тайм в том числе. [3391.24-3398.52] Какие-то модельки, обученные Flash Attention, обычно показывают рост производительности в три с половиной раза. [3398.52-3375.00]  [3377.76-3381.48] С чем это вдруг связано? С тем, что у нас подсчет нашего социального сообщества
[3400.00-3408.28] это вдруг связано с тем что у нас подсчет нашего салфеттен шина на самом деле он очень не [3408.28-3415.04] оптимизирован по памяти от слова совсем у него есть несколько операций операция там матричного [3415.04-3421.66] перемножения операция взять и софт макса и операции еще одного матричного там перемножения но не суть [3421.66-3428.92] важно какого потому что она нигде в целом особо не оптимизируется вот и на самом деле подсчет софт [3428.92-3400.00]  [3401.08-NA] Макса и вот этот.
[3425.00-3431.20] И на самом деле почет софтмакса и вот это матричное приложение, [3431.20-3435.38] которое первое наших коверисов, очень затратное. [3435.38-3439.58] И обычно, как оно делается во всех фреймворках, они [3439.58-3447.50] ее пихают в называемую там «Hardband with Memory» внутри GPU. [3447.50-3453.54] Нашу GPU можно представить как какую-то consistent память, [3453.54-3425.00]  [3426.44-NA] какой-то, как будто бы жесткий дебил.
[3450.00-3456.84] какую-то consistent память наш какой-то как будто бы жесткий диск внутри джипу и есть какая-то [3456.84-3464.62] оперативка внутри джипу несмотря на то что полтора терабайта в секунду кажется гопухи это все равно [3464.62-3471.76] этого какие скорости но на самом деле на огромных там пайлов данных и так далее это сильно замедляет [3471.76-3477.40] процесс там и обучение всего остального когда у нас при этом есть очень маленькая потому что там [3477.40-3450.00]  [3452.58-NA] там всего 20 мб обычно, но при этом очень много.
[3475.00-3480.58] при этом есть очень маленькая потому что там всего 20 гигабайт обычно но при этом очень пропускная по [3480.58-3491.02] своей способности виртуальная память внутри нашей гипухи и flash attention они очень эффективно [3491.02-3497.14] научились работать с этим небольшим кусочком как раз таки связанным с видео оперативной памятью [3497.14-3475.00]  [3482.38-NA] они вся основная суть почему вдруг этот кусочек стал использоваться
[3500.00-3504.70] Вся основная суть, почему вдруг этот кусочек стал использоваться, [3505.04-3508.34] ведь на него вроде не положишь целую матрицу, [3508.34-3515.30] а это в рамках самой первой реализации Flash Attention, [3515.76-3520.78] в рамках перемножения матриц использования тайлинга, [3521.82-3527.94] когда мы вместо подсчетов, когда мы считаем Q на K, [3528.16-3500.00]  [3501.96-NA] мы обычно там матрицу перемножаем
[3525.00-3529.90] Когда мы считаем Q на K, мы обычно матрицу перемножаем, [3530.04-3531.66] как мы знаем, как мы их перемножаем. [3531.66-3534.32] Там используется просто более эффективный метод, [3534.70-3539.80] который резко сокращает количество операций, но это окей. [3541.52-3548.66] В рамках подсчета как раз-таки Softmax используется так называемый онлайн Softmax, [3549.58-3552.66] который считается у нас рекуррентно. [3553.52-3525.00]  [3527.32-NA] И именно благодаря сфере развития, мы можем сделать
[3550.00-3558.34] считается у нас рекуррентно, и именно благодаря свойству рекуррентности при подсчете онлайн софтмакса [3558.34-3567.78] мы очень хорошо и эффективно умеем хранить информацию как раз-таки о текущем рекуррентном состоянии этого софтмакса [3567.78-3576.04] в очень быстрой памяти, и это нам позволяет как раз-таки вот эти две операции тайлинга и онлайн софтмакса, [3576.22-3550.00]  [3553.82-NA] во-первых, не просто быстро считать, так еще и
[3575.00-3582.56] онлайн софтмакса во-первых не просто быстро считать так еще и производить вычисления на одном ядре гпу [3582.56-3591.00] при всем при этом прошлое все наши вычисления они слова парализовались сейчас это проявляются [3591.00-3597.32] просто прекрасно так что вот на одном там ядре гпу это все дело считается и виду как раз таки [3597.32-3575.00]  [3582.50-NA] этого мы заметили там сильный прирост flash оттеншин 2 flash оттеншин 3 и по там
[3600.00-3607.80] Flash Attention 2, Flash Attention 3 и прочие какие-то модернизации подобных флешей, [3608.18-3614.58] они так или иначе продолжают идею авторов изначального Flash Attention. [3615.24-3620.38] Но Flash Attention сейчас в той или иной реализации нет ни одной, наверное, лампки, [3620.38-3621.84] которая бы не использовала его. [3623.08-3623.84] Не знаю, правда. [3624.40-3625.58] Поэтому он сейчас везде. [3627.10-3629.80] И при этом все мы не теряем качество от слова совсем никак, [3629.96-3600.00]  [3601.00-NA] рак.
[3625.00-3631.06] сейчас везде и при этом все мы не теряем качестве от слова совсем никак потому что мы получаем ровно [3631.06-3637.72] тот же результат то есть это действительно очень хорошая оптимизация работы алгоритма причем не по [3637.72-3643.32] там какой-то компетенции на класт то есть мы в целом имеем ту же сложность алгоритма которые [3643.32-3649.42] была у нас до этого мы очень сильно имеем ниже требования по памяти которые требуются нам для [3649.42-3625.00]  [3628.04-NA] для подсчета как раз-таки Attention Scarf.
[3650.00-3660.98] как раз таки attention скоров ну и теперь кого кэш стараюсь быстренько по нему пройти идея очень [3660.98-3666.68] простая как у нас работает лампка у нас есть изначальный какой-то запрос это примеру два [3666.68-3674.96] плюс два она отсылается лампки лампка генерирует будет теперь два плюс два будет равно два плюс [3674.96-3650.00]  [3655.00-NA] 2 равно 4 по виду того что ну ломка у нас обычно это деколь
[3675.00-3682.44] равно 4 по виду того что новая лампу у нас обычно это декодер она всегда берет какое-то предыдущее [3682.44-3688.60] свое состояние и на основании это предыдущее состояние генерирует следующий токен и так [3688.60-3698.10] итеративно недурно можно заметить что на самом деле у нас есть в достаточно повторяющиеся куски [3698.10-3675.00]  [3681.72-NA] даже не так мы вот эти все куски
[3700.00-3702.82] Точнее, даже не так. [3702.82-3707.22] Мы вот эти все куски, которые у нас были там в качестве [3707.22-3711.16] запроса, в качестве ответа, мы можем очень эффективно [3711.16-3712.16] где-то хранить. [3712.16-3715.60] Уже не дурно как идея. [3715.60-3719.82] А теперь развеем эту идею совсем до крайностей. [3719.82-3722.96] А почему бы нам просто вот эти куски кода не хранить [3722.96-3726.40] в каком-то кэше, который у нас будет постоянно обновляться, [3726.40-3729.38] а именно этот кэш, который у нас всегда заложен как [3729.38-3700.00]  [3701.00-NA] значения.
[3725.00-3730.76] постоянно обновляться а именно этот кэш который у нас всегда заложен как значение мы будем подавать [3730.76-3742.46] всегда в л.м. качестве входного какого-то контекста то есть просто базового хранить этот весь кэш [3742.46-3751.78] будет куда удобнее и куда более быстрой какой-то реализации чем мы будем заново скармливать модели [3751.78-3725.00]  [3728.42-NA] или весь предыдущий какой-то контекст, ведь у нас в целом есть...
[3750.00-3756.60] заново скармливать модели весь предыдущий какой-то контекст ведь у нас в целом есть по киваю уже [3756.60-3766.08] какие-то данные от модели которые мы можем есть достаточно эффективно скармливать это особенно [3766.08-3774.96] важно для time to first о кино но точнее наоборот не сильно важно потому что у нас первый контекст [3774.96-3750.00]  [3753.42-3754.68] текст декодинга у нас никуда не пойдет, у нас ковер-краш появится только после этого.
[3775.00-3779.66] текст-декодинг у нас никуда не пойдет, у нас KV-кэш появится только после этого. [3780.12-3783.02] Однако этот способ сильно увеличивает ТПС, [3785.28-3791.42] но в целом особо сильно никак не влияет в своем первоначальном виде на использование памяти. [3791.82-3796.90] У нас все равно резервируется больше 30% на любой видюхе под KV-кэш. [3796.90-3775.00]  [3783.10-NA] Однако, что очень важно, что вдруг научились его очень хорошо квантизовывать и оптимизировать.
[3800.00-3805.08] что вдруг научились его очень хорошо квантизовывать и оптимизировать. [3805.88-3810.74] У нас была проблема, что изначально веса модели при маленьких контекстах, [3811.52-3817.48] то есть при маленьком кавэкэше, они у нас занимали большую часть памяти, [3817.88-3822.26] понятное дело, но этот кавэкэш при больших контекстах сильно растет, [3822.86-3827.00] так что у нас не хватает памяти на эффективное хранение весов. [3827.34-3800.00]  [3802.98-NA] И поэтому научились кавыкаш-квантификации.
[3825.00-3833.58] памяти на эффективное хранение весов не поэтому научились кого кэш квантизовать причем с помощью [3833.58-3842.90] квантизации кого кэша можно во-первых сохранить те же самые результаты по модели которые используются [3842.90-3850.24] но при этом сильно сократив потребление памяти на хранение кого кэша и текущие как раз таки [3850.24-3825.00]  [3829.76-NA] О реализации квантизации КВ-кавша, КВ-квант просто
[3850.00-3856.48] таки реализации там квантизации кого каша там кого квант просто и называется они позволяют [3856.48-3862.90] он достичь как раз таки ломком на продакшене там контекстного окна в 10 миллионов токен ровно [3862.90-3868.24] потому что вот это оптимизировали кого кэш он хорошо поместится на любую железяку и [3868.24-3877.54] последнее что мы раз а мы просто типов каждым на каждом шаге мы просто конка чем в последнем [3877.54-3850.00]  [3852.46-NA] В конец добавляем...
[3875.00-3883.28] каждом шаге мы просто конка чем в последнем в конец добавляем имбединг токина да да все просто [3883.28-3890.26] очень просто все так то есть тут нет какого-то супер но шестая ли гениальной идеи просто обратили [3890.26-3895.46] внимание что он в целом по какие-то куски текста они постоянно повторяются их решили отдельно в [3895.46-3903.52] каком-то кэше хранить значение там ключ значения по ним все тут ничего супер особенного нету вот [3903.52-3875.00]  [3876.50-NA] вот этот KVC, он просто отвечает за это.
[3900.00-3906.72] Тут ничего супер-особенного нету. Вот этот KVCash просто отвечает за какой-то контекст, который на [3906.72-3912.78] каждом шаге модель сама себе дает. Вот она может к нему очень эффективно быстро обратиться. [3912.78-3921.72] С помощью квантизации он еще и весить мало начинает. Да, и последняя история тоже, она просто более [3921.72-3927.84] умная квантизация, нежели чем там просто заквантить весы и найти какой-то фактор квантизации. Это там [3927.84-3900.00]  [3902.16-NA] ЛЛМ-Инт-8.
[3925.00-3931.90] и найти какой-то фактор квантизации это там ллм-инт8 там прям так называется вот [3931.90-3943.06] что делают смотрят на значение в любой на самом деле матрицы находят как и какие-то условные [3943.06-3949.78] обычные значения внутри матрицы которые как-то равномерно распределены между самими собой но [3949.78-3954.62] матрицы мы также еще и чаще всего находим какие-то аутлайеры чаще всего из-за того что у нас [3954.62-3925.00]  [3925.36-NA] саду.
[3950.00-3954.62] мы также еще и чаще всего находим какие-то аутлайеры. Чаще всего из-за того, что у нас [3954.62-3962.00] достаточно спортированные порой бывают эмбеддинги, у нас эти аутлайеры действительно хранят какую-то [3962.00-3969.38] супер ключевую информацию для лмпи. Поэтому было предложено, давайте мы на самом деле наши аутлайеры, [3969.38-3976.16] в виду того, что они несут достаточно большую смысловую нагрузку для наших моделей, не будем [3976.16-3950.00]  [3953.84-NA] никак трогать в рамках квантизации, потому что из-за, там, квантизации
[3975.00-3982.96] Не будем никак трогать в рамках квантизации, потому что из-за квантизации подобных параметров сильно потом может пострадать качество. [3983.58-3984.72] Мы оставим их как есть. [3986.52-3994.92] И действительно, можно эти вещи оставить как есть, но при этом заняться квантизацией не аутлайеров, [3995.44-3999.50] а просто каких-то значений, которые так или иначе в нашем алгоритме распределены. [3999.50-3975.00]  [3980.50-NA] со стандартным алгоритмом квантизации, и потом все это дело...
[4000.00-4006.46] По стандартному алгоритму квантизации и потом все это дело уметь эффективно объединять. [4007.66-4015.34] Подробнее про алгоритм, то, как он выбирает аутлайеры, то, как он выбирает регулярные значения, тут решил не касаться. [4015.66-4018.06] Но идея тоже достаточно простая, интуитивная. [4019.94-4027.72] И на самом деле очень весомая, потому что зачастую все современные реализации, которые можно скачать с Hugging Face, [4027.72-4000.00]  [4002.28-NA] они поддерживают LMint 8.
[4025.00-4031.38] Современные реализации, которые можно скачать с Hugging Face, они поддерживают Element 8 внутри себя, [4031.38-4038.88] и это дает еще меньшую просадку по качеству, чем при обычной квантизации полноценной. [4039.64-4049.70] И при этом все позволяет сильно меньше памяти потреблять модели на инференции, на обучении и так далее. [4051.54-4025.00]  [4030.28-NA] Нам осталось поговорить по поводу фреймворка.
[4050.00-4061.32] Нам осталось поговорить по поводу фреймворков, на которых работают разработчики, которые выводят модели в прод. [4062.58-4073.04] У нас есть несколько фреймворков, которые точно хотелось бы затронуть, не суперподробно, но просто хотя бы рассказать, которые все опенсорсники так или иначе используют. [4073.04-4050.00]  [4056.94-NA] это тендер это л это больше такой продакшен на самом деле фреймворк эти фреймворки
[4075.00-4078.00] Это больше такой продакшн, на самом деле, фреймворк. [4079.36-4081.26] Эти фреймворки все в целом зачем-то нужны. [4081.60-4086.86] Они объединяют все то, что мы там обсудили до этого, [4089.42-4091.62] то есть какие-то методы оптимизации, [4091.84-4095.38] какие-то ускорения инференса, поддержка стабильности [4095.38-4098.16] и функциональности нашего сервиса, [4098.72-4100.02] как раз-таки внутри себя, [4100.60-4075.00]  [4079.96-NA] имеют хорошую поддержку на каком-то...
[4100.00-4106.34] имеют хорошую поддержку на каком-то более низком уровне, [4106.44-4108.24] то есть по общению с железяками. [4108.42-4112.40] К примеру, TensorRT, это непосредственно разработано NVIDIA, [4112.90-4114.88] оно поддерживает самые современные ядра. [4114.88-4119.24] Если выкатывается драйвер на какой-нибудь H100 GPU, [4119.62-4121.72] на который вы будете учить свою модель, [4121.82-4124.68] то, скорее всего, TensorRT обновится сиюсекундно, [4125.06-4127.98] и у вас будет самая современная поддержка без багов и так далее. [4128.24-4100.00]  [4102.26-NA] В отличие от всех других фреймворков, которые мы
[4125.00-4127.98] И у вас будет там самая современная поддержка без багов и так далее. [4128.24-4133.38] В отличие от всех других фреймворков, потому что они зачастую просто реализованы китайцами, [4133.56-4136.96] у которых хоть и есть какие-то свои GPU, они не так распространены, [4136.96-4142.38] и все равно все метятся в как раз-таки использовании GPU от NVIDIA. [4142.98-4148.20] При этом все, TensorFlow RT, он production фреймворк в первую очередь, [4148.70-4150.62] и у него очень сложный порог входа. [4151.14-4125.00]  [4129.38-NA] Не каждая лаборатория может позволить себе вдруг взять специалистов.
[4150.00-4156.66] порог входа. Не каждая лаборатория может позволить себе вдруг взять специалиста по этому фреймву [4156.66-4164.92] и как-то на нем работать, продолжать. Зачастую самым популярным это VLLM используется. [4165.04-4173.80] У него очень простой сам по себе. У него хорошая скорость как раз-таки, [4173.80-4178.90] и инференсы модели после определенных операций, которые этот фреймворк делает. [4179.52-4150.00]  [4151.10-NA] появляет.
[4175.00-4181.60] там после определенных операций которые этот фреймворк делает авторы вы как раз реализовали [4181.60-4190.80] по патч тэншин патч тэншин нам очень эффективно позволяет работать с кого кишон в удивление вот [4190.80-4198.44] блочно как-то реализуют там какую-то структуру там по хранению этого к вкша в не особо разбираюсь [4198.44-4175.00]  [4181.16-NA] честно вот очень популярный это можно по звездочкам увидеть его
[4200.00-4208.70] очень популярный это можно по звездочкам увидеть его зачастую используют все современные там ломки [4208.70-4217.22] которые не супер большие они там на в лами так иначе написаны есть еще и ломде плой первые [4217.22-4224.18] ребята которые там запустили там ламу один ламу 2 то сделали там от авторы континент бачинга тоже [4224.18-4200.00]  [4205.76-NA] простой но гениальной идеи, тоже какой-то фреймворк. Вот они есть.
[4225.00-4235.14] гениальные идеи, тоже какой-то фреймворк. Вот они есть такие. И заключительно, что хотелось бы сказать, [4235.14-4242.24] а именно сделать какой-то определенный рекап, зачем мы это вообще вдруг все прошли на протяжении всех [4242.24-4250.38] этих пяти лекций, ведь что нас дальше ждет. Мы в целом поговорили на самой первой лекции, что там [4250.38-4225.00]  [4229.52-NA] генеративный искусственный интеллект это круто есть определенные понятно дело грехи
[4250.00-4252.02] там генеративный искусственный интеллект [4252.02-4254.10] это круто, но есть определенные, [4254.20-4255.78] понятное дело, грехи на текущий момент, [4255.92-4257.42] есть какие-то нерешенные у него проблемы, [4258.02-4259.82] но что немаловажно, [4260.08-4261.00] то, что [4261.00-4264.12] есть определенные риски, которые [4264.12-4265.88] являются не просто [4265.88-4268.06] рисками, что мы там денежку какую-то [4268.06-4269.84] потеряем, но это [4269.84-4272.48] там топ-2 рисков по версии [4272.48-4274.36] там международного [4274.36-4275.98] экономического форума, [4275.98-4277.72] такой самой большой, наверное, [4277.80-4279.54] организации, которая там [4279.54-4250.00]  [4250.46-NA] так и не может.
[4275.00-4282.74] форума такой самый большой наверное организации которые там так или иначе занимается тем что [4282.74-4287.66] подсвечивают какие-то риски мировые именно к чему все прислушиваются там самой большой компании так [4287.66-4294.86] далее то есть это очень авторитетный источник да и эти риски связаны с галлюцинациями считают [4294.86-4301.70] сильно не просто галлюцинациями но и дезинформации считают очень опасными и очень важно нам [4301.70-4275.00]  [4278.30-NA] нам добросовестно и очень качественно мерить в таком случае алан.
[4300.00-4307.02] и очень важно нам добросовестно и очень качественно мерить в таком случае LLM. Мы поговорили на [4307.02-4315.02] второй лекции про то, что используют вообще в рамках обучения LLM и какие модификации делают [4315.02-4322.58] над LLM-ками, которые так или иначе влияют на работу самой LLM и их нужно учитывать. Вообще, [4322.58-4328.66] в целом, что нужно уметь все правильно измерять, нужно не просто вслепую бросаться на первый [4328.66-4300.00]  [4301.32-NA] попавшийся бенчмарк на уметь.
[4325.00-4330.40] измерять нужно не просто вслепую бросаться на первый попавшийся бичмарк но уметь как-то его [4330.40-4337.06] оценить оценить особенности нашей лампки что она может что не может не используйте где она не [4337.06-4345.82] может она там обучить ее тоже определенным образом и до рассмотрели модальности как следующий шаг [4345.82-4352.48] развития общих целых всех алла лампок некоторые нюансы связанных с их обучениями о том что [4352.48-4325.00]  [4327.52-NA] что модальность — это не просто какой-то блокбокс.
[4350.00-4351.76] нюансы, связанных с их обучениями, [4351.98-4353.88] о том, что модальность — это не просто [4353.88-4355.76] какой-то блокбокс, но это [4355.76-4357.86] все-таки состоящий из [4357.86-4359.78] каких-то различных [4359.78-4361.50] энкодеров, проекторов, там, [4361.58-4362.76] cross-attention в истории, [4363.32-4365.72] и то, что их [4365.72-4367.88] качество измерить — это достаточно большой [4367.88-4369.90] челлендж. Ну и сегодня поговорили в целом [4369.90-4371.26] о каких-то [4371.26-4373.80] методах оптимизации, которые [4373.80-4376.06] так или иначе используются, [4377.30-4377.42] и [4377.42-4379.90] которые могут нам так или иначе [4379.90-4350.00]  [4351.00-NA] беды.
[4375.00-4383.64] и которые могут нам так или иначе повлиять на картину что мы можем увидеть что там хайф модельки [4383.64-4388.82] которые мы загружаем там с ген фейса они могут отличаться того что мы это можем увидеть на [4388.82-4397.26] сервисе и поэтому от этого нам собственно правильно как надо строить наше тестирование все дальнейшие [4397.26-4375.00]  [4380.10-4382.72] Следующие лекции проведут Ваня Подпружников и Степан Пономарев, мои коллеги.
[4400.00-4404.10] Пани Подпружников и Степан Пономарев, мои коллеги. [4404.68-4410.02] В дальнейшем вас ждет достаточно увлекательное и долгое путешествие мир раков, агентов, [4410.02-4418.18] и не просто ЛЛМ, а так таковой, но и их применений, как они правильно используются, [4419.24-4423.02] как их правильно использовать, как узнать, что они правильно используются. [4424.54-4400.00]  [4405.86-NA] и проговорим про какие-то реальные истории жизни.
[4425.00-4428.90] проговорим про какие-то реальные истории жизни. [4430.34-4436.22] Степан, как раз-таки по большей части сконцентрированный на диффузионных моделях, [4436.32-4437.38] расскажет ровно про них. [4438.42-4444.58] Скорее всего, там самый современный доклад будет связан с текстом видео, [4444.86-4447.08] той вещью, которая развивается меньше года. [4448.70-4451.52] Посмотрим на методы как раз-таки оценки подобных моделей, [4451.52-4454.68] какие риски там тоже могут быть, что с этим делать.
[4450.00-4452.56] раз такие оценки подобных моделей, какие риски там [4452.56-4454.68] тоже могут быть, что с этим делать. [4454.98-4457.54] И если все пойдет гладко, то, возможно, пройдем бонусную [4457.54-4458.42] лекцию, о которой говорили. [4459.60-4462.60] Сразу предвкушая вопрос про домашнее здание, появится [4462.60-4463.16] ли оно сегодня. [4463.54-4465.64] На самом деле нет, не появится, появится оно в субботу. [4466.22-4466.44] Вот. [4467.40-4468.66] На все, что хотел сказать. [4469.20-4470.64] Так, всем спасибо. [4471.02-4472.70] Если есть вопросы, буду рад слышать. [4476.24-4478.14] А есть какое-то понимание, про что домашнее здание [4478.14-4478.30] будет? [4479.16-4479.84] Да, есть.
[4475.00-4478.32] А есть какое-то понимание, про что домашка-то будет? [4479.14-4479.86] Да, есть. [4481.44-4485.00] Обычно домашка будет состоять из... [4486.88-4489.16] У вас будет, скорее всего, инференция ллмки, [4490.20-4493.38] достаточно быстрой, очень надеюсь на это. [4494.44-4500.44] И нужно будет эту ллмку уметь прогнать на бенчмарках, [4500.44-4504.36] которые мы обсуждали как раз-таки в рамках этих лекций.
[4500.00-4506.90] бенчмарках, которые мы обсуждали как раз-таки в рамках этих лекций, возможно, в различных режимах, [4508.58-4509.84] и написать по этому какие-то выгоды. [4510.36-4512.50] В целом, это будет ровно про это. [4513.84-4514.26] Спасибо. [4515.02-4516.02] Сверхъестественного, да. [4521.28-4524.18] Здесь сейчас еще есть вопросы, буду рад ответить. [4524.36-4527.24] Но если вдруг нет, то пишите в чат. [4528.64-4500.00]  [4502.76-NA] И тогда всем спасибо.
[4525.00-4527.24] вдруг нет, то пишите в чат. [4528.64-4529.78] И тогда всем спасибо. [4531.04-4532.54] Получается, Ваня начнет с четверга, [4533.24-4535.88] а по поводу первого домашнего задания [4535.88-4537.84] сброшу как раз-таки на неделю информацию. [4539.44-4540.62] Всем хорошего вечера. [4545.82-4546.78] Спасибо, пока.